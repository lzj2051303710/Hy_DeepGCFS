{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9b3da8-b14c-4126-9ae1-e2aa68f73d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.neural_network as nn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn import svm\n",
    "from stability_selection import RandomizedLasso\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from minepy import MINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f8c42fa-0d86-45ec-a1a2-0229ea703ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(fileName):\n",
    "    '''\n",
    "    read file\n",
    "\n",
    "    param fileName: XXX.xlsx \n",
    "    return: dataset_name, X, Y, feature_names\n",
    "    '''\n",
    "    dataset_name = fileName.split('.')[0]\n",
    "    data = pd.read_csv(fileName, header=None, sep='\\t', low_memory=False).T\n",
    "    feature_names = data.iloc[0, 1:].values\n",
    "    X = data.iloc[1: , 1:].apply(pd.to_numeric, axis=0).values\n",
    "    Y = preprocessing.LabelEncoder().fit_transform(data.iloc[1:, 0].values)\n",
    "    # If there is a null value in X, delete the column with null value\n",
    "    if np.isnan(X).any():\n",
    "        # Locate the null value in X\n",
    "        nanrow, nancol = np.where(np.isnan(X))\n",
    "        nancol = np.unique(nancol)\n",
    "        print(\"null value：\", nancol)\n",
    "        # Delete columns with null values\n",
    "        X = np.delete(X, nancol, axis=1)\n",
    "        feature_names = np.delete(feature_names, nancol)\n",
    "\n",
    "    # threshold = 0.85\n",
    "    # k = 10\n",
    "    # X, feature_names = kmeans(X, feature_names, k, threshold)\n",
    "    # X, feature_names = preTtest(X, Y, feature_names, threshold)\n",
    "    # X, feature_names = premic(X, Y, feature_names, threshold)\n",
    "    return dataset_name, X, Y, feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7611c707-d1e3-47f5-ac6f-238643d978ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_info(X, Y):\n",
    "    '''\n",
    "    get information of dataset\n",
    "\n",
    "    return: Number of positive samples, negative samples, total samples and features\n",
    "    '''\n",
    "    total_num = len(Y)\n",
    "    pos_num = np.sum((Y == 1).astype(int))\n",
    "    neg_num = np.sum((Y == 0).astype(int))\n",
    "    feature_num = X.shape[1]\n",
    "    return pos_num, neg_num, total_num, feature_num\n",
    "\n",
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2603b645-dd67-466f-9c26-ce304096cd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(X, feature_names, k, threshold):\n",
    "    '''\n",
    "    The feature is removed by KMeans\n",
    "   :return: Features after removing redundancy\n",
    "    '''\n",
    "    print(\"KM之前：\", X.shape)\n",
    "    scaler = StandardScaler()\n",
    "    km_x = scaler.fit_transform(X)\n",
    "     num_clusters = k\n",
    "    my_threshold = 1 - threshold\n",
    "    clusters_name = [[] for i in range(num_clusters)]\n",
    "    clusters_index = [[] for i in range(num_clusters)]\n",
    "    model_km = KMeans(n_clusters=num_clusters)\n",
    "    km_result = list(model_km.fit_predict(km_x.T))\n",
    "    features = list(zip(feature_names, km_result, list(range(km_x.shape[1]))))\n",
    "    for feature in features:\n",
    "        clusters_name[feature[1]].append(feature[0])\n",
    "        clusters_index[feature[1]].append(feature[2])\n",
    "    \n",
    "     cluster_seeds = [min(cluster) for cluster in clusters_index]\n",
    "    print(\"簇中种子点的index：\", cluster_seeds)\n",
    "      node_scores = [[] for i in range(num_clusters)]\n",
    "    for i in range(num_clusters):\n",
    "        node_num = len(clusters_name[i])\n",
    "        seed_feature = X[:, cluster_seeds[i]]\n",
    "        j = 0\n",
    "        for j in clusters_index[i]:\n",
    "            index = j\n",
    "            score = np.corrcoef(X[:, index], seed_feature.T)\n",
    "            # 记录协方差\n",
    "            node_scores[i].append(np.abs(score[0, 1]))\n",
    "        temp_cluster_scores = list(zip(clusters_index[i], clusters_name[i], node_scores[i]))\n",
    "        temp_cluster_scores.sort(key=lambda a: a[2], reverse=True)\n",
    "        if node_num > 1.0 / my_threshold:\n",
    "            del temp_cluster_scores[1:int(node_num * my_threshold + 0.5) + 1]\n",
    "        clusters_index[i] = [x[0] for x in temp_cluster_scores]\n",
    "        clusters_name[i] = [x[1] for x in temp_cluster_scores]\n",
    "\n",
    "    result_index = []\n",
    "    result_name = []\n",
    "    for l in clusters_index:\n",
    "        result_index += [i for i in l]\n",
    "    for n in clusters_name:\n",
    "        result_name += n\n",
    "    result_x = X[:, result_index]\n",
    "    print(\"KM之后的：\", result_x.shape)\n",
    "    return result_x, result_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5fd1e4be-b578-487e-b9eb-52796adcbeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 根据互信息进行预处理\n",
    "def premic(X, Y, feature_names, threshold):\n",
    "    ###设置数目\n",
    "    num = round(X.shape[1] * threshold)\n",
    "    print(\"mic预处理之后的数量：\", num)\n",
    "    # num = 1000\n",
    "    mine = MINE()\n",
    "    mic_scores = []\n",
    "    for i in range(X.shape[1]):\n",
    "        # i = i+1\n",
    "        mine.compute_score(X[:,i], Y)\n",
    "        m = mine.mic()\n",
    "        mic_scores.append(m)\n",
    "    mic_result = dict(zip(feature_names, mic_scores))\n",
    "    mic_result_df = pd.DataFrame([mic_result]).T\n",
    "    mic_sorted = mic_result_df.sort_values(axis=0, by=[0], ascending=False)\n",
    "    mic_result = mic_sorted.iloc[0:num, :]\n",
    "\n",
    "    temp_index = []\n",
    "    # print(type(np.array(mic_result.index)),type(feature_names), np.array(mic_result.index))\n",
    "    for name in mic_result.index:\n",
    "        # print(name,X[:,list(feature_names).index(name)])\n",
    "        temp_index.append(list(feature_names).index(name))\n",
    "    minc_X = X[:,temp_index]\n",
    "    return minc_X, np.array(mic_result.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff8725c8-974d-4196-ad04-7513525e6f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTtest(X, Y, feature_names, threshold):\n",
    "    '''\n",
    "   \n",
    "    :return: X，feature_names\n",
    "    '''\n",
    "    print(X.shape, Y.shape)\n",
    "       X_Y = pd.DataFrame(np.concatenate((Y.reshape([-1,1]), X), axis=1)).sort_values(by=0)\n",
    "    #　print(type(X_Y), X_Y)\n",
    "    ttest_x = X_Y.iloc[0:, 1:].apply(pd.to_numeric, axis=0).values\n",
    "    ttest_y = X_Y.iloc[0:, 0].values\n",
    "    pos_num = np.sum(ttest_y == 0)\n",
    "    print(\"正样本\",pos_num)\n",
    "    temp_x = np.split(ttest_x,[pos_num])\n",
    "    pos_X = temp_x[0]\n",
    "    neg_X = temp_x[1]\n",
    "    feature_p = []\n",
    "    # 记录P值小于0.05的数量\n",
    "    count = 0\n",
    "    for j in range(ttest_x.shape[1]):\n",
    "        t,p = ttest_ind(pos_X[:,j], neg_X[:,j])\n",
    "        # (j,feature_names[j],t,p)\n",
    "        feature_p.append(p)\n",
    "        if p < 0.05: count += 1\n",
    "    temp_features = list(zip(ttest_x.T, feature_names, feature_p))\n",
    "    for i in list(zip(feature_names, feature_p)):\n",
    "        print(i)\n",
    "    temp_features.sort(key=lambda a:a[2], reverse=False)\n",
    "    filter_features = temp_features[0: round(X.shape[1] * threshold)]\n",
    "    ttest_X = np.array([a[0] for a in filter_features]).T\n",
    "    ttest_names = np.array([a[1] for a in filter_features])\n",
    "    print(count, \"筛选之后的基因：\", ttest_names)\n",
    "    # print(new_X[:,0:30])\n",
    "    return ttest_X, ttest_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56881f7e-6765-4709-94cd-a8dd84275664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stab\n",
    "def stab_handler(X, Y, feature_names, num):\n",
    "    '''\n",
    "    select the best num features by stability selection\n",
    "\n",
    "    return: selected x and features\n",
    "    '''\n",
    "    print(\"stab的大小：\",X.shape)\n",
    "    rlasso = RandomizedLasso(alpha=0.0001, max_iter=1000)\n",
    "    rlasso.fit(X, Y)\n",
    "    importance = np.abs(rlasso.coef_)\n",
    "    # mm = MinMaxScaler()\n",
    "    # mm.fit(importance)\n",
    "    result = list(zip(feature_names, importance))\n",
    "    result.sort(key=lambda a: a[1], reverse=True)\n",
    "    # print(\"stab:\", result)\n",
    "    stab_result = result[:num]\n",
    "    # Select the corresponding data information according to the selected protein name\n",
    "    temp = []\n",
    "    selected_names = []\n",
    "    selected_weights = []\n",
    "    for temp_feature in stab_result:\n",
    "        temp.append(list(feature_names).index(temp_feature[0]))\n",
    "        selected_names.append(temp_feature[0])\n",
    "        selected_weights.append(temp_feature[1])\n",
    "    x = X[:, temp]\n",
    "    selected_weights = np.array(selected_weights).reshape(-1, 1)\n",
    "    mm = MinMaxScaler()\n",
    "    selected_weights = mm.fit_transform(selected_weights)\n",
    "    return x, selected_names, selected_weights.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ab9e537-3b34-489a-88fc-00893afb5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lasso\n",
    "def lasso_handler(X, Y, feature_names, num):\n",
    "    '''\n",
    "    select the best num features by Lasso\n",
    "\n",
    "    return: selected x and features\n",
    "    '''\n",
    "    lasso = Lasso(alpha=1e-10, max_iter=1000)\n",
    "    lasso.fit(X, Y)\n",
    "    importance = np.abs(lasso.coef_)\n",
    "    result = list(zip(feature_names, importance))\n",
    "    result.sort(key=lambda a: a[1], reverse=True)\n",
    "    lasso_result = result[:num]\n",
    "    temp = []\n",
    "    selected_names = []\n",
    "    selected_weights = []\n",
    "    for temp_feature in lasso_result:\n",
    "        temp.append(list(feature_names).index(temp_feature[0]))\n",
    "        selected_names.append(temp_feature[0])\n",
    "        selected_weights.append(temp_feature[1])\n",
    "    x = X[:, temp]\n",
    "    selected_weights = np.array(selected_weights).reshape(-1, 1)\n",
    "    mm = MinMaxScaler()\n",
    "    selected_weights = mm.fit_transform(selected_weights)\n",
    "    return x, selected_names, selected_weights.reshape(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c374df03-c527-4d4a-9d39-44e7b42508cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the score of the model\n",
    "def model_score(model, X, Y):\n",
    "    model_accs = []\n",
    "\n",
    "    # 留一法\n",
    "    loo = LeaveOneOut()\n",
    "    scores = 0\n",
    "    for train_index, test_index in loo.split(X, Y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        model.fit(X_train, y_train)\n",
    "        model_accs.append(model.score(X_test, y_test))\n",
    "\n",
    "    return np.array(model_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa1c1e73-7664-40ae-b66f-36592dc10f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lasso + SVM\n",
    "def lasso_svm(X, Y, feature_names, num):\n",
    "    # select features by lasso\n",
    "    lasso_X, lasso_feature_names, feature_weights = lasso_handler(X, Y, feature_names, num)\n",
    "    model_svm = svm.SVC(max_iter=1000, kernel='rbf')\n",
    "    model_scores = model_score(model_svm, lasso_X, Y)\n",
    "    return lasso_feature_names, feature_weights, model_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc2648d7-e0a3-4b93-9a1a-14e19f74f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lasso + NN\n",
    "def lasso_nn(X, Y, feature_names, num):\n",
    "    # select features by lasso\n",
    "    lasso_X, lasso_feature_names, feature_weights = lasso_handler(X, Y, feature_names, num)\n",
    "    model_nn = nn.MLPClassifier(activation='tanh', solver='adam', alpha=0.0001, learning_rate='adaptive',\n",
    "                                learning_rate_init=0.001, max_iter=1000)\n",
    "    model_scores = model_score(model_nn, lasso_X, Y)\n",
    "    return lasso_feature_names, feature_weights, model_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f6830dd-0e08-42fc-8d6c-7801a1143600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stab + SVM\n",
    "def stab_svm(X, Y, feature_names, num):\n",
    "    # select features by stab\n",
    "    stab_X, stab_feature_names, feature_weights = stab_handler(X, Y, feature_names, num)\n",
    "    model_svm = svm.SVC(max_iter=1000, kernel='rbf')\n",
    "    model_scores = model_score(model_svm, stab_X, Y)\n",
    "    return stab_feature_names, feature_weights, model_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b459134-ba73-4a80-83ac-976e366dd9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stab + NN\n",
    "def stab_nn(X, Y, feature_names, num):\n",
    "    # select features by stab\n",
    "    stab_X, stab_feature_names, feature_weights = stab_handler(X, Y, feature_names, num)\n",
    "    model_nn = nn.MLPClassifier(activation='tanh', solver='adam', alpha=0.0001, learning_rate='adaptive',\n",
    "                                learning_rate_init=0.001, max_iter=1000)\n",
    "    model_scores = model_score(model_nn, stab_X, Y)\n",
    "    return stab_feature_names, feature_weights, model_scores\n",
    "\n",
    "# feature count\n",
    "def featrue_count(selected_result):\n",
    "    dict = {}\n",
    "    for f in selected_result:\n",
    "        dict[f[0]] = dict.get(f[0], 0) + f[1]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5751e157-8d17-4bcd-bd73-47baf8acd33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = 'real.txt'\n",
    "dataset_name, X, Y, feature_names = read_file(fileName)\n",
    "print(\"文件（数据）名称：%s\" % dataset_name)\n",
    "pos_num, neg_num, total_num, feature_num = file_info(X, Y)\n",
    "print(\"正样本数：%s, 负样本数：%s, 总样本数：%d, 特征数：%d\" % (pos_num, neg_num, total_num, feature_num))\n",
    "\n",
    "writer = pd.ExcelWriter(r'realResult\\kmeans\\result_kmeans.xlsx')\n",
    "filename = r'realResult\\\\kmeans\\\\' + dataset_name + '_kmeans.txt'  ####################################################文件位置\n",
    "print(\"文件名：\", filename)\n",
    "f = open(filename, mode='w', encoding='utf8')  #################################\n",
    "f.write('当前数据集为:' + dataset_name + '\\n*******************************************************\\n')\n",
    "\n",
    "# The number of features selected is 10\n",
    "num = 10\n",
    "# 定义稳定性选择重复的次数\n",
    "stab_num = 100\n",
    "# methonds\n",
    "lasso_svm_feature_names, lasso_svm_feature_weights, lasso_svm_model_scores = lasso_svm(X, Y, feature_names, num)\n",
    "print(\"方法名：Lasso+SVM\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\"\n",
    "      %(lasso_svm_feature_names, lasso_svm_feature_weights, lasso_svm_model_scores.mean(), lasso_svm_model_scores))\n",
    "f.write(\"方法名：Lasso+SVM\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\\n\"\n",
    "      %(lasso_svm_feature_names, lasso_svm_feature_weights, lasso_svm_model_scores.mean(), lasso_svm_model_scores))\n",
    "lasso_svm_dict = featrue_count(list(zip(lasso_svm_feature_names, lasso_svm_feature_weights )))\n",
    "lasso_svm_df = pd.DataFrame.from_dict(lasso_svm_dict, orient='index', columns=['weight'])\n",
    "lasso_svm_df = lasso_svm_df.reset_index().rename(columns={'index':'lasso+svm'})\n",
    "lasso_svm_df.to_excel(excel_writer=writer, sheet_name='Lasso+SVM', index=False)\n",
    "# print(lasso_svm_df)\n",
    "\n",
    "lasso_nn_feature_names, lasso_nn_feature_weights, lasso_nn_model_scores = lasso_nn(X, Y, feature_names, num)\n",
    "print(\"方法名：Lasso+NN\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\"\n",
    "      %(lasso_nn_feature_names, lasso_nn_feature_weights, lasso_nn_model_scores.mean(), lasso_nn_model_scores))\n",
    "f.write(\"方法名：Lasso+NN\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\\n\"\n",
    "      %(lasso_nn_feature_names, lasso_nn_feature_weights, lasso_nn_model_scores.mean(), lasso_nn_model_scores))\n",
    "lasso_nn_dict = featrue_count(list(zip(lasso_nn_feature_names, lasso_nn_feature_weights )))\n",
    "lasso_nn_df = pd.DataFrame.from_dict(lasso_nn_dict, orient='index', columns=['weight'])\n",
    "lasso_nn_df = lasso_nn_df.reset_index().rename(columns={'index':'lasso+nn'})\n",
    "lasso_nn_df.to_excel(excel_writer=writer, sheet_name='Lasso+NN', index=False)\n",
    "\n",
    "stab_svm_names = []\n",
    "stab_svm_weight = []\n",
    "stab_svm_count = 0\n",
    "f.write(\"***************************stab+SVM******************************\\n\")\n",
    "for i in range(stab_num):\n",
    "    threshold = 0.842\n",
    "    k = 8\n",
    "    km_x, km_names = kmeans(X, feature_names, k, threshold)\n",
    "    # X, feature_names = preTtest(X, Y, feature_names, threshold)\n",
    "    # X, feature_names = premic(X, Y, feature_names, threshold)\n",
    "    stab_svm_feature_names, stab_svm_feature_weights, stab_svm_model_scores = stab_svm(km_x, Y, km_names, num)\n",
    "    print(\"方法名：Stab_SVM\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\"\n",
    "          %(stab_svm_feature_names, stab_svm_feature_weights, stab_svm_model_scores.mean(), stab_svm_model_scores))\n",
    "    f.write(\"方法名：Stab_SVM\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\\n\"\n",
    "          %(stab_svm_feature_names, stab_svm_feature_weights, stab_svm_model_scores.mean(), stab_svm_model_scores))\n",
    "    if np.sum(stab_svm_model_scores) == 6:\n",
    "        stab_svm_count += 1\n",
    "        stab_svm_names += stab_svm_feature_names\n",
    "        stab_svm_weight += stab_svm_feature_weights.tolist()\n",
    "f.write(\"方法Stab+SVM全中的次数为：%d\\n\" % stab_svm_count)\n",
    "# 计数次数\n",
    "stab_svm_count_df = pd.DataFrame(pd.value_counts(stab_svm_names),columns=['count'])\n",
    "stab_svm_count_df = stab_svm_count_df.reset_index().rename(columns={'index':'id'})\n",
    "stab_svm_count_df.to_excel(excel_writer=writer, sheet_name='Stab+SVM_count', index=False)\n",
    "# 计数权重\n",
    "stab_svm_dict = featrue_count(list(zip(stab_svm_names, stab_svm_weight )))\n",
    "stab_svm_weight_df = pd.DataFrame.from_dict(stab_svm_dict, orient='index', columns=['weight'])\n",
    "stab_svm_weight_df = stab_svm_weight_df.reset_index().rename(columns={'index':'id'})\n",
    "stab_svm_weight_df = stab_svm_weight_df.sort_values(by='weight', ascending=False)\n",
    "stab_svm_weight_df.to_excel(excel_writer=writer, sheet_name='Stab+SVM_weight', index=False)\n",
    "\n",
    "\n",
    "stab_nn_names = []\n",
    "stab_nn_weight = []\n",
    "stab_nn_count = 0\n",
    "f.write(\"***************************stab+NN******************************\\n\")\n",
    "for i in range(stab_num):\n",
    "    threshold = 0.842\n",
    "    k = 8\n",
    "    km_x, km_names = kmeans(X, feature_names, k, threshold)\n",
    "    stab_nn_feature_names, stab_nn_feature_weights, stab_nn_model_scores = stab_nn(km_x, Y, km_names, num)\n",
    "    print(\"方法名：Stab+NN\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\"\n",
    "          % (stab_nn_feature_names, stab_nn_feature_weights, stab_nn_model_scores.mean(), stab_nn_model_scores))\n",
    "    f.write(\"方法名：Stab+NN\\n选择的特征：%s\\n特征的权重：%s\\n平均准确率：%.4f\\t%s\\n\\n\"\n",
    "            % (stab_nn_feature_names, stab_nn_feature_weights, stab_nn_model_scores.mean(), stab_nn_model_scores))\n",
    "    if np.sum(stab_nn_model_scores) == 6:\n",
    "        stab_nn_count += 1\n",
    "        stab_nn_names += stab_nn_feature_names\n",
    "        stab_nn_weight += stab_nn_feature_weights.tolist()\n",
    "f.write(\"方法Stab+NN全中的次数为：%d\\n\" % stab_nn_count)\n",
    "\n",
    "stab_nn_count_df = pd.DataFrame(pd.value_counts(stab_nn_names),columns=['count'])\n",
    "stab_nn_count_df = stab_nn_count_df.reset_index().rename(columns={'index':'id'})\n",
    "stab_nn_count_df.to_excel(excel_writer=writer, sheet_name='Stab+NN_count', index=False)\n",
    "stab_nn_dict = featrue_count(list(zip(stab_nn_names, stab_nn_weight )))\n",
    "\n",
    "stab_nn_weight_df = pd.DataFrame.from_dict(stab_nn_dict, orient='index', columns=['weight'])\n",
    "stab_nn_weight_df = stab_nn_weight_df.reset_index().rename(columns={'index':'id'})\n",
    "stab_nn_weight_df = stab_nn_weight_df.sort_values(by='weight', ascending=False)\n",
    "stab_nn_weight_df.to_excel(excel_writer=writer, sheet_name='Stab+NN_weight', index=False)\n",
    "\n",
    "print(\"svm:\",stab_svm_count_df)\n",
    "print(\"nn:\",stab_nn_count_df)\n",
    "\n",
    "f.close()\n",
    "\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcac4e-70b9-4e77-8b5d-62186af00de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zongjin",
   "language": "python",
   "name": "zongjin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
